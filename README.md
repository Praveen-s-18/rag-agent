# ğŸ”§ Gemini RAG - Tool-Calling Q&A on PDF

This project demonstrates a **Retrieval-Augmented Generation (RAG)** pipeline powered by **Google Gemini**, built using **LangChain tools**, **FAISS vector search**, and a **Streamlit UI**.

You can upload a PDF, and the app will extract, chunk, embed, and retrieve relevant sections to answer your questions using Gemini.

---

## ğŸ“Œ Features

- ğŸ“„ Upload PDF documents
- âœ‚ï¸ Chunk and embed text using Sentence Transformers
- ğŸ” Vector-based semantic search with FAISS
- ğŸ’¬ Question-answering via Google Gemini (`gemini-pro`)
- ğŸ§  Modular, tool-based design using LangChain's `@tool` decorator
- âš¡ Interactive frontend using Streamlit

---

## ğŸ§  What is RAG?

**Retrieval-Augmented Generation (RAG)** is a technique that improves LLM responses by retrieving relevant information from external documents and feeding it into the model as context.

Instead of relying on the modelâ€™s internal memory alone, it dynamically pulls relevant content to generate more accurate, grounded answers.

---

## ğŸ› ï¸ How It Works

1. **PDF Upload** â€“ Load your document.
2. **Text Chunking** â€“ Break it into manageable segments.
3. **Embedding** â€“ Convert text into vector representations.
4. **Semantic Search** â€“ Match your question to the most relevant chunks.
5. **Gemini Q&A** â€“ Provide the context to Gemini and get a natural language response.

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/gemini-rag-pdf.git
cd gemini-rag-pdf
